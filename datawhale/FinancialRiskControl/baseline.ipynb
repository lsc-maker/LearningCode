{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import gc\n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "from catboost import CatBoostRegressor\n",
    "from sklearn.linear_model import SGDRegressor, LinearRegression, Ridge\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import math\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import StratifiedKFold, KFold\n",
    "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score, log_loss\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('./Data/train.csv')\n",
    "testA = pd.read_csv('./Data/testA.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>loanAmnt</th>\n",
       "      <th>term</th>\n",
       "      <th>interestRate</th>\n",
       "      <th>installment</th>\n",
       "      <th>grade</th>\n",
       "      <th>subGrade</th>\n",
       "      <th>employmentTitle</th>\n",
       "      <th>employmentLength</th>\n",
       "      <th>homeOwnership</th>\n",
       "      <th>...</th>\n",
       "      <th>n5</th>\n",
       "      <th>n6</th>\n",
       "      <th>n7</th>\n",
       "      <th>n8</th>\n",
       "      <th>n9</th>\n",
       "      <th>n10</th>\n",
       "      <th>n11</th>\n",
       "      <th>n12</th>\n",
       "      <th>n13</th>\n",
       "      <th>n14</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>35000.0</td>\n",
       "      <td>5</td>\n",
       "      <td>19.52</td>\n",
       "      <td>917.97</td>\n",
       "      <td>E</td>\n",
       "      <td>E2</td>\n",
       "      <td>320.0</td>\n",
       "      <td>2 years</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>9.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>18000.0</td>\n",
       "      <td>5</td>\n",
       "      <td>18.49</td>\n",
       "      <td>461.90</td>\n",
       "      <td>D</td>\n",
       "      <td>D2</td>\n",
       "      <td>219843.0</td>\n",
       "      <td>5 years</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>12000.0</td>\n",
       "      <td>5</td>\n",
       "      <td>16.99</td>\n",
       "      <td>298.17</td>\n",
       "      <td>D</td>\n",
       "      <td>D3</td>\n",
       "      <td>31698.0</td>\n",
       "      <td>8 years</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>11000.0</td>\n",
       "      <td>3</td>\n",
       "      <td>7.26</td>\n",
       "      <td>340.96</td>\n",
       "      <td>A</td>\n",
       "      <td>A4</td>\n",
       "      <td>46854.0</td>\n",
       "      <td>10+ years</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>16.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>3000.0</td>\n",
       "      <td>3</td>\n",
       "      <td>12.99</td>\n",
       "      <td>101.07</td>\n",
       "      <td>C</td>\n",
       "      <td>C2</td>\n",
       "      <td>54.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 47 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  loanAmnt  term  interestRate  installment grade subGrade  \\\n",
       "0   0   35000.0     5         19.52       917.97     E       E2   \n",
       "1   1   18000.0     5         18.49       461.90     D       D2   \n",
       "2   2   12000.0     5         16.99       298.17     D       D3   \n",
       "3   3   11000.0     3          7.26       340.96     A       A4   \n",
       "4   4    3000.0     3         12.99       101.07     C       C2   \n",
       "\n",
       "   employmentTitle employmentLength  homeOwnership  ...    n5    n6    n7  \\\n",
       "0            320.0          2 years              2  ...   9.0   8.0   4.0   \n",
       "1         219843.0          5 years              0  ...   NaN   NaN   NaN   \n",
       "2          31698.0          8 years              0  ...   0.0  21.0   4.0   \n",
       "3          46854.0        10+ years              1  ...  16.0   4.0   7.0   \n",
       "4             54.0              NaN              1  ...   4.0   9.0  10.0   \n",
       "\n",
       "     n8   n9   n10  n11  n12  n13  n14  \n",
       "0  12.0  2.0   7.0  0.0  0.0  0.0  2.0  \n",
       "1   NaN  NaN  13.0  NaN  NaN  NaN  NaN  \n",
       "2   5.0  3.0  11.0  0.0  0.0  0.0  4.0  \n",
       "3  21.0  6.0   9.0  0.0  0.0  0.0  1.0  \n",
       "4  15.0  7.0  12.0  0.0  0.0  0.0  4.0  \n",
       "\n",
       "[5 rows x 47 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.concat([train, testA], axis=0, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['A', 'B', 'C', 'D', 'E', 'F', 'G']\n",
      "['A1', 'A2', 'A3', 'A4', 'A5', 'B1', 'B2', 'B3', 'B4', 'B5', 'C1', 'C2', 'C3', 'C4', 'C5', 'D1', 'D2', 'D3', 'D4', 'D5', 'E1', 'E2', 'E3', 'E4', 'E5', 'F1', 'F2', 'F3', 'F4', 'F5', 'G1', 'G2', 'G3', 'G4', 'G5']\n"
     ]
    }
   ],
   "source": [
    "print(sorted(data['grade'].unique()))\n",
    "print(sorted(data['subGrade'].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1 year        65671\n",
       "10+ years    328525\n",
       "2 years       90565\n",
       "3 years       80163\n",
       "4 years       59818\n",
       "5 years       62645\n",
       "6 years       46582\n",
       "7 years       44230\n",
       "8 years       45168\n",
       "9 years       37866\n",
       "< 1 year      80226\n",
       "NaN           58541\n",
       "Name: employmentLength, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['employmentLength'].value_counts(dropna=False).sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['employmentLength'].replace(to_replace='10+ years', value='10 years', inplace=True)\n",
    "data['employmentLength'].replace('< 1 year', '0 years', inplace=True)\n",
    "\n",
    "def employmentLength_to_int(s):\n",
    "    if pd.isnull(s):\n",
    "        return s\n",
    "    else:\n",
    "        return np.int8(s.split()[0])\n",
    "    \n",
    "data['employmentLength'] = data['employmentLength'].apply(employmentLength_to_int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0      80226\n",
       "1.0      65671\n",
       "2.0      90565\n",
       "3.0      80163\n",
       "4.0      59818\n",
       "5.0      62645\n",
       "6.0      46582\n",
       "7.0      44230\n",
       "8.0      45168\n",
       "9.0      37866\n",
       "10.0    328525\n",
       "NaN      58541\n",
       "Name: employmentLength, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['employmentLength'].value_counts(dropna=False).sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "592794    Nov-2000\n",
       "494436    Mar-2001\n",
       "525336    Apr-2000\n",
       "168534    Aug-1990\n",
       "580794    Jan-2000\n",
       "Name: earliesCreditLine, dtype: object"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['earliesCreditLine'].sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['earliesCreditLine'] = data['earliesCreditLine'].apply(lambda s: int(s[-4:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    1000000.000000\n",
       "mean        1998.688632\n",
       "std            7.606231\n",
       "min         1944.000000\n",
       "25%         1995.000000\n",
       "50%         2000.000000\n",
       "75%         2004.000000\n",
       "max         2015.000000\n",
       "Name: earliesCreditLine, dtype: float64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['earliesCreditLine'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>annualIncome</th>\n",
       "      <th>applicationType</th>\n",
       "      <th>delinquency_2years</th>\n",
       "      <th>dti</th>\n",
       "      <th>earliesCreditLine</th>\n",
       "      <th>employmentLength</th>\n",
       "      <th>employmentTitle</th>\n",
       "      <th>ficoRangeHigh</th>\n",
       "      <th>ficoRangeLow</th>\n",
       "      <th>grade</th>\n",
       "      <th>...</th>\n",
       "      <th>pubRecBankruptcies</th>\n",
       "      <th>purpose</th>\n",
       "      <th>regionCode</th>\n",
       "      <th>revolBal</th>\n",
       "      <th>revolUtil</th>\n",
       "      <th>subGrade</th>\n",
       "      <th>term</th>\n",
       "      <th>title</th>\n",
       "      <th>totalAcc</th>\n",
       "      <th>verificationStatus</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>110000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>17.05</td>\n",
       "      <td>2001</td>\n",
       "      <td>2.0</td>\n",
       "      <td>320.0</td>\n",
       "      <td>734.0</td>\n",
       "      <td>730.0</td>\n",
       "      <td>E</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>32</td>\n",
       "      <td>24178.0</td>\n",
       "      <td>48.9</td>\n",
       "      <td>E2</td>\n",
       "      <td>5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>46000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>27.83</td>\n",
       "      <td>2002</td>\n",
       "      <td>5.0</td>\n",
       "      <td>219843.0</td>\n",
       "      <td>704.0</td>\n",
       "      <td>700.0</td>\n",
       "      <td>D</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>15096.0</td>\n",
       "      <td>38.9</td>\n",
       "      <td>D2</td>\n",
       "      <td>5</td>\n",
       "      <td>1723.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>74000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>22.77</td>\n",
       "      <td>2006</td>\n",
       "      <td>8.0</td>\n",
       "      <td>31698.0</td>\n",
       "      <td>679.0</td>\n",
       "      <td>675.0</td>\n",
       "      <td>D</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>4606.0</td>\n",
       "      <td>51.8</td>\n",
       "      <td>D3</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>118000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>17.21</td>\n",
       "      <td>1999</td>\n",
       "      <td>10.0</td>\n",
       "      <td>46854.0</td>\n",
       "      <td>689.0</td>\n",
       "      <td>685.0</td>\n",
       "      <td>A</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "      <td>11</td>\n",
       "      <td>9948.0</td>\n",
       "      <td>52.6</td>\n",
       "      <td>A4</td>\n",
       "      <td>3</td>\n",
       "      <td>4.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>29000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>32.16</td>\n",
       "      <td>1977</td>\n",
       "      <td>NaN</td>\n",
       "      <td>54.0</td>\n",
       "      <td>694.0</td>\n",
       "      <td>690.0</td>\n",
       "      <td>C</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10</td>\n",
       "      <td>21</td>\n",
       "      <td>2942.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>C2</td>\n",
       "      <td>3</td>\n",
       "      <td>11.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 49 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   annualIncome  applicationType  delinquency_2years    dti  \\\n",
       "0      110000.0                0                 0.0  17.05   \n",
       "1       46000.0                0                 0.0  27.83   \n",
       "2       74000.0                0                 0.0  22.77   \n",
       "3      118000.0                0                 0.0  17.21   \n",
       "4       29000.0                0                 0.0  32.16   \n",
       "\n",
       "   earliesCreditLine  employmentLength  employmentTitle  ficoRangeHigh  \\\n",
       "0               2001               2.0            320.0          734.0   \n",
       "1               2002               5.0         219843.0          704.0   \n",
       "2               2006               8.0          31698.0          679.0   \n",
       "3               1999              10.0          46854.0          689.0   \n",
       "4               1977               NaN             54.0          694.0   \n",
       "\n",
       "   ficoRangeLow grade  ...  pubRecBankruptcies  purpose  regionCode  revolBal  \\\n",
       "0         730.0     E  ...                 0.0        1          32   24178.0   \n",
       "1         700.0     D  ...                 0.0        0          18   15096.0   \n",
       "2         675.0     D  ...                 0.0        0          14    4606.0   \n",
       "3         685.0     A  ...                 0.0        4          11    9948.0   \n",
       "4         690.0     C  ...                 0.0       10          21    2942.0   \n",
       "\n",
       "   revolUtil  subGrade term   title  totalAcc  verificationStatus  \n",
       "0       48.9        E2    5     1.0      27.0                   2  \n",
       "1       38.9        D2    5  1723.0      18.0                   2  \n",
       "2       51.8        D3    5     0.0      27.0                   2  \n",
       "3       52.6        A4    3     4.0      28.0                   1  \n",
       "4       32.0        C2    3    11.0      27.0                   2  \n",
       "\n",
       "[5 rows x 49 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "grade 类型数： 7\n",
      "subGrade 类型数： 35\n",
      "employmentTitle 类型数： 298101\n",
      "homeOwnership 类型数： 6\n",
      "verificationStatus 类型数： 3\n",
      "purpose 类型数： 14\n",
      "postCode 类型数： 935\n",
      "regionCode 类型数： 51\n",
      "applicationType 类型数： 2\n",
      "initialListStatus 类型数： 2\n",
      "title 类型数： 47903\n",
      "policyCode 类型数： 1\n"
     ]
    }
   ],
   "source": [
    "# 部分类别特征\n",
    "cate_features = ['grade', 'subGrade', 'employmentTitle', 'homeOwnership', 'verificationStatus', 'purpose', 'postCode', 'regionCode', \\\n",
    "                 'applicationType', 'initialListStatus', 'title', 'policyCode']\n",
    "for f in cate_features:\n",
    "    print(f, '类型数：', data[f].nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 类型数在2之上，又不是高维稀疏的\n",
    "data = pd.get_dummies(data, columns=['grade', 'subGrade', 'homeOwnership', 'verificationStatus', 'purpose', 'regionCode'], drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 高维类别特征需要进行转换\n",
    "for f in ['employmentTitle', 'postCode', 'title']:\n",
    "    data[f+'_cnts'] = data.groupby([f])['id'].transform('count')\n",
    "    data[f+'_rank'] = data.groupby([f])['id'].rank(ascending=False).astype(int)\n",
    "    del data[f]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [f for f in data.columns if f not in ['id','issueDate','isDefault']]\n",
    "\n",
    "train = data[data.isDefault.notnull()].reset_index(drop=True)\n",
    "test = data[data.isDefault.isnull()].reset_index(drop=True)\n",
    "\n",
    "x_train = train[features]\n",
    "x_test = test[features]\n",
    "\n",
    "y_train = train['isDefault']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cv_model(clf, train_x, train_y, test_x, clf_name):\n",
    "    folds = 5\n",
    "    seed = 2020\n",
    "    kf = KFold(n_splits=folds, shuffle=True, random_state=seed)\n",
    "\n",
    "    train = np.zeros(train_x.shape[0])\n",
    "    test = np.zeros(test_x.shape[0])\n",
    "\n",
    "    cv_scores = []\n",
    "\n",
    "    for i, (train_index, valid_index) in enumerate(kf.split(train_x, train_y)):\n",
    "        print('************************************ {} ************************************'.format(str(i+1)))\n",
    "        trn_x, trn_y, val_x, val_y = train_x.iloc[train_index], train_y[train_index], train_x.iloc[valid_index], train_y[valid_index]\n",
    "\n",
    "        if clf_name == \"lgb\":\n",
    "            train_matrix = clf.Dataset(trn_x, label=trn_y)\n",
    "            valid_matrix = clf.Dataset(val_x, label=val_y)\n",
    "\n",
    "            params = {\n",
    "                'boosting_type': 'gbdt',\n",
    "                'objective': 'binary',\n",
    "                'metric': 'auc',\n",
    "                'min_child_weight': 5,\n",
    "                'num_leaves': 2 ** 5,\n",
    "                'lambda_l2': 10,\n",
    "                'feature_fraction': 0.8,\n",
    "                'bagging_fraction': 0.8,\n",
    "                'bagging_freq': 4,\n",
    "                'learning_rate': 0.1,\n",
    "                'seed': 2020,\n",
    "                'nthread': 28,\n",
    "                'n_jobs':24,\n",
    "                'silent': True,\n",
    "                'verbose': -1,\n",
    "            }\n",
    "\n",
    "            model = clf.train(params, train_matrix, 50000, valid_sets=[train_matrix, valid_matrix], verbose_eval=200,early_stopping_rounds=200)\n",
    "            val_pred = model.predict(val_x, num_iteration=model.best_iteration)\n",
    "            test_pred = model.predict(test_x, num_iteration=model.best_iteration)\n",
    "            \n",
    "            # print(list(sorted(zip(features, model.feature_importance(\"gain\")), key=lambda x: x[1], reverse=True))[:20])\n",
    "                \n",
    "        if clf_name == \"xgb\":\n",
    "            train_matrix = clf.DMatrix(trn_x , label=trn_y)\n",
    "            valid_matrix = clf.DMatrix(val_x , label=val_y)\n",
    "            test_matrix = clf.DMatrix(test_x)\n",
    "            \n",
    "            params = {'booster': 'gbtree',\n",
    "                      'objective': 'binary:logistic',\n",
    "                      'eval_metric': 'auc',\n",
    "                      'gamma': 1,\n",
    "                      'min_child_weight': 1.5,\n",
    "                      'max_depth': 5,\n",
    "                      'lambda': 10,\n",
    "                      'subsample': 0.7,\n",
    "                      'colsample_bytree': 0.7,\n",
    "                      'colsample_bylevel': 0.7,\n",
    "                      'eta': 0.04,\n",
    "                      'tree_method': 'exact',\n",
    "                      'seed': 2020,\n",
    "                      'nthread': 36,\n",
    "                      \"silent\": True,\n",
    "                      }\n",
    "            \n",
    "            watchlist = [(train_matrix, 'train'),(valid_matrix, 'eval')]\n",
    "            \n",
    "            model = clf.train(params, train_matrix, num_boost_round=50000, evals=watchlist, verbose_eval=200, early_stopping_rounds=200)\n",
    "            val_pred  = model.predict(valid_matrix, ntree_limit=model.best_ntree_limit)\n",
    "            test_pred = model.predict(test_matrix , ntree_limit=model.best_ntree_limit)\n",
    "                 \n",
    "        if clf_name == \"cat\":\n",
    "            params = {'learning_rate': 0.05, 'depth': 5, 'l2_leaf_reg': 10, 'bootstrap_type': 'Bernoulli',\n",
    "                      'od_type': 'Iter', 'od_wait': 50, 'random_seed': 11, 'allow_writing_files': False}\n",
    "            \n",
    "            model = clf(iterations=20000, **params)\n",
    "            model.fit(trn_x, trn_y, eval_set=(val_x, val_y),\n",
    "                      cat_features=[], use_best_model=True, verbose=500)\n",
    "            \n",
    "            val_pred  = model.predict(val_x)\n",
    "            test_pred = model.predict(test_x)\n",
    "            \n",
    "        train[valid_index] = val_pred\n",
    "        test = test_pred / kf.n_splits\n",
    "        cv_scores.append(roc_auc_score(val_y, val_pred))\n",
    "        \n",
    "        print(cv_scores)\n",
    "       \n",
    "    print(\"%s_scotrainre_list:\" % clf_name, cv_scores)\n",
    "    print(\"%s_score_mean:\" % clf_name, np.mean(cv_scores))\n",
    "    print(\"%s_score_std:\" % clf_name, np.std(cv_scores))\n",
    "    return train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lgb_model(x_train, y_train, x_test):\n",
    "    lgb_train, lgb_test = cv_model(lgb, x_train, y_train, x_test, \"lgb\")\n",
    "    return lgb_train, lgb_test\n",
    "\n",
    "def xgb_model(x_train, y_train, x_test):\n",
    "    xgb_train, xgb_test = cv_model(xgb, x_train, y_train, x_test, \"xgb\")\n",
    "    return xgb_train, xgb_test\n",
    "\n",
    "def cat_model(x_train, y_train, x_test):\n",
    "    cat_train, cat_test = cv_model(CatBoostRegressor, x_train, y_train, x_test, \"cat\") \n",
    "    return cat_train, cat_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "************************************ 1 ************************************\n",
      "[LightGBM] [Warning] num_threads is set with n_jobs=24, nthread=28 will be ignored. Current value: num_threads=24\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[200]\ttraining's auc: 0.742591\tvalid_1's auc: 0.730355\n",
      "[400]\ttraining's auc: 0.755118\tvalid_1's auc: 0.731459\n",
      "[600]\ttraining's auc: 0.766238\tvalid_1's auc: 0.731846\n",
      "[800]\ttraining's auc: 0.776359\tvalid_1's auc: 0.731758\n",
      "Early stopping, best iteration is:\n",
      "[669]\ttraining's auc: 0.76993\tvalid_1's auc: 0.731896\n",
      "[0.7318963815365425]\n",
      "************************************ 2 ************************************\n",
      "[LightGBM] [Warning] num_threads is set with n_jobs=24, nthread=28 will be ignored. Current value: num_threads=24\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[200]\ttraining's auc: 0.743824\tvalid_1's auc: 0.726889\n",
      "[400]\ttraining's auc: 0.756668\tvalid_1's auc: 0.728177\n",
      "[600]\ttraining's auc: 0.767686\tvalid_1's auc: 0.728401\n",
      "Early stopping, best iteration is:\n",
      "[476]\ttraining's auc: 0.761101\tvalid_1's auc: 0.72858\n",
      "[0.7318963815365425, 0.7285796452663349]\n",
      "************************************ 3 ************************************\n",
      "[LightGBM] [Warning] num_threads is set with n_jobs=24, nthread=28 will be ignored. Current value: num_threads=24\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[200]\ttraining's auc: 0.74319\tvalid_1's auc: 0.73177\n",
      "[400]\ttraining's auc: 0.755312\tvalid_1's auc: 0.732725\n",
      "[600]\ttraining's auc: 0.766226\tvalid_1's auc: 0.733131\n",
      "Early stopping, best iteration is:\n",
      "[578]\ttraining's auc: 0.765234\tvalid_1's auc: 0.733189\n",
      "[0.7318963815365425, 0.7285796452663349, 0.7331893899140796]\n",
      "************************************ 4 ************************************\n",
      "[LightGBM] [Warning] num_threads is set with n_jobs=24, nthread=28 will be ignored. Current value: num_threads=24\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[200]\ttraining's auc: 0.742927\tvalid_1's auc: 0.730407\n",
      "[400]\ttraining's auc: 0.755259\tvalid_1's auc: 0.731306\n",
      "[600]\ttraining's auc: 0.766367\tvalid_1's auc: 0.731652\n",
      "[800]\ttraining's auc: 0.776424\tvalid_1's auc: 0.73161\n",
      "Early stopping, best iteration is:\n",
      "[687]\ttraining's auc: 0.770834\tvalid_1's auc: 0.731715\n",
      "[0.7318963815365425, 0.7285796452663349, 0.7331893899140796, 0.7317151139148783]\n",
      "************************************ 5 ************************************\n",
      "[LightGBM] [Warning] num_threads is set with n_jobs=24, nthread=28 will be ignored. Current value: num_threads=24\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[200]\ttraining's auc: 0.743419\tvalid_1's auc: 0.729327\n",
      "[400]\ttraining's auc: 0.756043\tvalid_1's auc: 0.730548\n",
      "[600]\ttraining's auc: 0.766566\tvalid_1's auc: 0.730922\n",
      "[800]\ttraining's auc: 0.776579\tvalid_1's auc: 0.730594\n",
      "Early stopping, best iteration is:\n",
      "[611]\ttraining's auc: 0.767229\tvalid_1's auc: 0.730972\n",
      "[0.7318963815365425, 0.7285796452663349, 0.7331893899140796, 0.7317151139148783, 0.7309722625300428]\n",
      "lgb_scotrainre_list: [0.7318963815365425, 0.7285796452663349, 0.7331893899140796, 0.7317151139148783, 0.7309722625300428]\n",
      "lgb_score_mean: 0.7312705586323757\n",
      "lgb_score_std: 0.001523232910780885\n"
     ]
    }
   ],
   "source": [
    "lgb_train, lgb_test = lgb_model(x_train, y_train, x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "************************************ 1 ************************************\n",
      "[0]\ttrain-auc:0.696113\teval-auc:0.696868\n",
      "Multiple eval metrics have been passed: 'eval-auc' will be used for early stopping.\n",
      "\n",
      "Will train until eval-auc hasn't improved in 200 rounds.\n",
      "[200]\ttrain-auc:0.727546\teval-auc:0.723833\n",
      "[400]\ttrain-auc:0.735156\teval-auc:0.727828\n",
      "[600]\ttrain-auc:0.740549\teval-auc:0.729809\n",
      "[800]\ttrain-auc:0.74474\teval-auc:0.730752\n",
      "[1000]\ttrain-auc:0.748749\teval-auc:0.731611\n",
      "[1200]\ttrain-auc:0.752245\teval-auc:0.732038\n"
     ]
    }
   ],
   "source": [
    "xgb_train, xgb_test = xgb_model(x_train, y_train, x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_train, cat_test = cat_model(x_train, y_train, x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rh_test = lgb_test*0.5 + xgb_test*0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testA['isDefault'] = rh_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testA[['id','isDefault']].to_csv('./Data/test_sub.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#简单投票\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
    "clf1 = LogisticRegression(random_state=1)\n",
    "clf2 = RandomForestClassifier(random_state=1)\n",
    "clf3 = XGBClassifier(learning_rate=0.1, n_estimators=150, max_depth=4, min_child_weight=2, subsample=0.7,objective='binary:logistic')\n",
    " \n",
    "vclf = VotingClassifier(estimators=[('lr', clf1), ('rf', clf2), ('xgb', clf3)])\n",
    "vclf = vclf .fit(x_train,y_train)\n",
    "print(vclf .predict(x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#加权投票\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
    "clf1 = LogisticRegression(random_state=1)\n",
    "clf2 = RandomForestClassifier(random_state=1)\n",
    "clf3 = XGBClassifier(learning_rate=0.1, n_estimators=150, max_depth=4, min_child_weight=2, subsample=0.7,objective='binary:logistic')\n",
    " \n",
    "vclf = VotingClassifier(estimators=[('lr', clf1), ('rf', clf2), ('xgb', clf3)], voting='soft', weights=[2, 1, 1])\n",
    "vclf = vclf .fit(x_train,y_train)\n",
    "print(vclf .predict(x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#stacking\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import itertools\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "from sklearn import datasets\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB \n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from mlxtend.classifier import StackingClassifier\n",
    "from sklearn.model_selection import cross_val_score, train_test_split\n",
    "from mlxtend.plotting import plot_learning_curves\n",
    "from mlxtend.plotting import plot_decision_regions\n",
    "\n",
    "\n",
    "# 以python自带的鸢尾花数据集为例\n",
    "iris = datasets.load_iris()\n",
    "X, y = iris.data[:, 1:3], iris.target\n",
    "\n",
    "\n",
    "clf1 = KNeighborsClassifier(n_neighbors=1)\n",
    "clf2 = RandomForestClassifier(random_state=1)\n",
    "clf3 = GaussianNB()\n",
    "lr = LogisticRegression()\n",
    "sclf = StackingClassifier(classifiers=[clf1, clf2, clf3], \n",
    "                          meta_classifier=lr)\n",
    "\n",
    "\n",
    "label = ['KNN', 'Random Forest', 'Naive Bayes', 'Stacking Classifier']\n",
    "clf_list = [clf1, clf2, clf3, sclf]\n",
    "    \n",
    "fig = plt.figure(figsize=(10,8))\n",
    "gs = gridspec.GridSpec(2, 2)\n",
    "grid = itertools.product([0,1],repeat=2)\n",
    "\n",
    "\n",
    "clf_cv_mean = []\n",
    "clf_cv_std = []\n",
    "for clf, label, grd in zip(clf_list, label, grid):\n",
    "        \n",
    "    scores = cross_val_score(clf, X, y, cv=5, scoring='accuracy')\n",
    "    print(\"Accuracy: %.2f (+/- %.2f) [%s]\" %(scores.mean(), scores.std(), label))\n",
    "    clf_cv_mean.append(scores.mean())\n",
    "    clf_cv_std.append(scores.std())\n",
    "        \n",
    "    clf.fit(X, y)\n",
    "    ax = plt.subplot(gs[grd[0], grd[1]])\n",
    "    fig = plot_decision_regions(X=X, y=y, clf=clf)\n",
    "    plt.title(label)\n",
    " \n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#blending\n",
    "# 以python自带的鸢尾花数据集为例\n",
    "data_0 = iris.data\n",
    "data = data_0[:100,:]\n",
    "\n",
    "\n",
    "target_0 = iris.target\n",
    "target = target_0[:100]\n",
    " \n",
    "#模型融合中基学习器\n",
    "clfs = [LogisticRegression(),\n",
    "        RandomForestClassifier(),\n",
    "        ExtraTreesClassifier(),\n",
    "        GradientBoostingClassifier()]\n",
    " \n",
    "#切分一部分数据作为测试集\n",
    "X, X_predict, y, y_predict = train_test_split(data, target, test_size=0.3, random_state=914)\n",
    "\n",
    "\n",
    "#切分训练数据集为d1,d2两部分\n",
    "X_d1, X_d2, y_d1, y_d2 = train_test_split(X, y, test_size=0.5, random_state=914)\n",
    "dataset_d1 = np.zeros((X_d2.shape[0], len(clfs)))\n",
    "dataset_d2 = np.zeros((X_predict.shape[0], len(clfs)))\n",
    " \n",
    "for j, clf in enumerate(clfs):\n",
    "    #依次训练各个单模型\n",
    "    clf.fit(X_d1, y_d1)\n",
    "    y_submission = clf.predict_proba(X_d2)[:, 1]\n",
    "    dataset_d1[:, j] = y_submission\n",
    "    #对于测试集，直接用这k个模型的预测值作为新的特征。\n",
    "    dataset_d2[:, j] = clf.predict_proba(X_predict)[:, 1]\n",
    "    print(\"val auc Score: %f\" % roc_auc_score(y_predict, dataset_d2[:, j]))\n",
    "\n",
    "\n",
    "#融合使用的模型\n",
    "clf = GradientBoostingClassifier()\n",
    "clf.fit(dataset_d1, y_d2)\n",
    "y_submission = clf.predict_proba(dataset_d2)[:, 1]\n",
    "print(\"Val auc Score of Blending: %f\" % (roc_auc_score(y_predict, y_submission)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "XGBoost-Sklearn",
   "language": "python",
   "name": "xgboost-sklearn"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
